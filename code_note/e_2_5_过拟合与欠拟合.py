# -*-coding:utf-8-*-


"""
机器学习中的一个重要问题便是模型的泛化能力（Generalization Ability），即模型对新鲜样本的适应能力。
泛化能力强的模型才是好模型。当模型在训练数据上表现良好但对不可见数据的泛化能力很差时，可能发生过拟合（Overfitting）。
若在训练集表现差，则在测试集表现同样会很差，这可能是由欠拟合（Underfitting）导致的
"""

"""
欠拟合解决方法
（1）增加新特征，可以考虑加入特征组合、高次特征，以此增大假设空间。
（2）添加多项式特征，这个在机器学习算法里用得很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。
（3）减少正则化参数，正则化的目的是用来防止过拟合，但是模型出现了欠拟合，则需要减少正则化参数。
（4）使用非线性模型，例如支持向量机、决策树、深度学习等模型。
（5）调整模型的容量（Capacity），通俗地讲，模型的容量是指其拟合各种函数的能力。
（6）容量低的模型可能很难拟合训练集；使用集成学习方法，如使用Bagging，可将多个弱学习器Bagging。
"""
"""
过拟合解决方法
（1）在神经网络模型中，可使用权值衰减的方法，即每次迭代过程中以某个小因子降低每个权值。
（2）选取合适的停止训练标准，使对机器的训练在合适的程度。
（3）保留验证数据集，对训练成果进行验证。
（4）获取额外数据进行交叉验证。
（5）正则化，即在进行目标函数或代价函数优化时，在目标函数或代价函数后面加上一个正则项，一般有L1正则与L2正则等
"""













